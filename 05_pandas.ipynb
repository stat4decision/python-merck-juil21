{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![image](./images/pandas.png)\n",
    "\n",
    "Pandas est le package de prédilection pour traiter des données structurées.\n",
    "\n",
    "Pandas est basé sur 2 structures extrêmement liées les Series et le DataFrame.\n",
    "\n",
    "Ces deux structures permettent de traiter des données sous forme de tableaux indexés.\n",
    "\n",
    "Les classes de Pandas utilisent des classes de Numpy, il est donc possible d'utiliser les fonctions universelles de Numpy sur les objets Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# on importe pandas avec :\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les Series de Pandas\n",
    "\n",
    "- Les Series sont indexées, c'est leur avantage sur les arrays de NumPy\n",
    "- On peut utiliser les fonctions `.values` et `.index` pour voir les différentes parties de chaque Series\n",
    "- On définit une Series par `pd.Series([,], index=['','',])`\n",
    "- On peut appeler un élément avec `ma_serie['France']`\n",
    "- On peut aussi faire des conditions :\n",
    "```python\n",
    "ma_serie[ma_serie>5000000]\n",
    "```\n",
    "```\n",
    "'France' in ma_serie\n",
    "```\n",
    "- Les objets Series peuvent être transformés en dictionnaires en utilisant :\n",
    "`.to_dict()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Définir un objet Series comprenant la population de 5 pays puis afficher les pays ayant une population > 50’000’000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_pop = pd.Series(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(ser_pop) == pd.Series\n",
    "print(\"Bien créée !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on construit une série avec les populations de plus de 50\n",
    "ser_pop_l50 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert ser_pop_l50.min() >= 50\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# D'autres opérations sur les objets series\n",
    "\n",
    "- Pour définir le nom de la Series, on utilise `.name`\n",
    "- Pour définir le titre de la colonne des observations, on utilise `.index.name`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Définir les noms de l’objet et de la colonne des pays pour la Series précédente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_pop.name = ___\n",
    "ser_pop.index.name = ___\n",
    "ser_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les données manquantes\n",
    "\n",
    "Dans pandas, les données manquantes sont identifiés avec les fonctions de Numpy (`np.nan`). On a d'autres fonctions telles que :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.isna(pd.Series([2,np.nan,4],index=['a','b','c']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.notna(pd.Series([2,np.nan,4],index=['a','b','c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les dates avec pandas\n",
    "\n",
    "- Python possède un module datetime qui permet de gérer facilement des dates\n",
    "- Pandas permet d'appliquer les opérations sur les dates aux Series et aux DataFrame\n",
    "- Le format es dates Python est `YYYY-MM-DD HH:MM:SS`\n",
    "\n",
    "- On peut générer des dates avec la fonction `pd.date_range()` avec différente fréquences `freq=`\n",
    "- On peut utiliser ces dates comme index dans un DataFrame ou dans un objet Series\n",
    "- On peut changer la fréquence en utilisant `.asfreq()`\n",
    "- Pour transformer une chaine de caractère en date, on utilise `pd.to_datetime()` avec l’option `dayfirst=True` si on est dans le cas français\n",
    "-On pourra aussi spécifier un format pour accélérer le processus `%Y%m%d`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "\n",
    "Créez un objet Series et ajoutez des dates partant du 3 octobre 2017 par jour jusqu’à aujourd’hui. Afficher le résultat dans un graphique (on utilisera la méthode `.plot()`\n",
    "\n",
    "*Indice :* Utilisez les informations ci-dessus\n",
    "\n",
    "On utilisera :\n",
    "```\n",
    "pd.date_range(___)\n",
    "np.random.randn(___)\n",
    "pd.Series(___)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_temp = pd.Series(___)\n",
    "serie_temp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert len(serie_temp) == 911\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Le DataFrame \n",
    "\n",
    "- Les DataFrame sont des objets très souples pouvant être construits de différentes façon\n",
    "- On peut les construire en récupérant des données copier / coller, où directement sur Internet, ou en entrant les valeurs manuellement\n",
    "\n",
    "\n",
    "- Les DataFrame se rapprochent des dictionnaires et on peut construire ces objets en utilisant `DataFrame(dico)`\n",
    "- De nombreux détails sur la création des DataFrame se trouve sur ce site :\n",
    "\n",
    "<http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Construction de DataFrame\n",
    "\n",
    "On peut simplement construire un DataFrame avec le classe pd.DataFrame() à partir de différentes structures :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "frame1=pd.DataFrame(np.random.randn(10).reshape(5,2),\n",
    "             index=[\"obs_\"+str(i) for i in range(5)],\n",
    "             columns=[\"col_\"+str(i) for i in range(2)])\n",
    "frame1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Opérations sur les DataFrame\n",
    "\n",
    "On peut afficher le nom des colonnes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(frame1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut accéder à une colonne avec :\n",
    "- `frame1.col_0` : attention au cas de nom de colonnes avec des espaces...\n",
    "- `frame1['col_0']`\n",
    "\n",
    "On peut accéder à une cellule avec :\n",
    "- `frame1.loc['obs1','col_0']` : on utilise les index et le nom des colonnes\n",
    "- `frame1.iloc[1,0]` : on utilise les positions dans le DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Options de visualisation et de résumé\n",
    "\n",
    "Pour afficher les 3 premières lignes, on peut utiliser :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "frame1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pour afficher un résumé du DF :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "frame1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Importer des données externes\n",
    "\n",
    "Pandas est l'outil le plus efficace pour importer des données externes, il prend en charge de nombreux formats dont csv, Excel, SQL, SAS...\n",
    "\n",
    "\n",
    "## Importation de données avec Pandas\n",
    "\n",
    "Quel que soit le type de fichier, Pandas possède une fonction :\n",
    "```python\n",
    "frame=pd.read_...('chemin_du_fichier/nom_du_fichier',...)\n",
    "```\n",
    "Pour écrire un DataFrame dans un fichier, on utilise :\n",
    "```python\n",
    "frame.to_...('chemin_du_fichier/nom_du_fichier',...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Importer un fichier `.csv` avec `pd.read_csv()`. On utilisera le fichier \"./data/airbnb.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert airbnb[\"price\"].dtype == object\n",
    "print(\"Bien importé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer un fichier `.csv` qui a comme séparateur `;`, le nom du fichier est `base-dpt.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dpt = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(base_dpt) == pd.DataFrame\n",
    "print(\"Bien importé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# D'autres types de données\n",
    "\n",
    "## JSON\n",
    "Les objets JSON ressemblent à des dictionnaires.\n",
    "\n",
    "On utilise le module `json` puis la fonction `json.loads()` pour transformer une entrée JSON en objet json\n",
    "\n",
    "## HTML\n",
    "On utilise `pd.read_html(url)`. Cet fonction est basée sur les packages `beautifulsoup` et `html5lib`\n",
    "\n",
    "Cette fonction renvoie une liste de DataFrame qui représentent tous les DataFrame de la page. On ira ensuite chercher l'élément qui nous intéresse avec `frame_list[0]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Importez un tableau en html depuis la page <http://www.fdic.gov/bank/individual/failed/banklist.html> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_bank = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_bank = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(frame_bank) == pd.DataFrame\n",
    "print(\"Bien importé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Importer depuis Excel\n",
    "\n",
    "On a deux approches pour Excel :\n",
    "- On peut utiliser `pd.read_excel()`\n",
    "- On peut utiliser la classe `pd.ExcelFile()`\n",
    "\n",
    "Dans ce cas, on utilise :\n",
    "```python\n",
    "xlsfile=pd.ExcelFile('fichier.xlsx')\n",
    "xlsfile.parse('Sheet1')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :** \n",
    "    \n",
    "Importez un fichier Excel avec les deux approches, on utilisera : `credit2.xlsx` et `ville.xls`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- avec `pd.read_excel()` pour le fichier `credit2.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit2 = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert credit2[\"Age\"].max() == 83\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- avec `pd.ExcelFile()` pour le fichier `ville.xls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ville_excel = pd.ExcelFile(___)\n",
    "frame_ville = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(frame_ville) = pd.DataFrame\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Importer des données SQL\n",
    "\n",
    "Pandas possède une fonction `read_sql()` qui permet d’importer directement des bases de données ou des queries dans des DataFrame\n",
    "\n",
    "Il faut tout de même un connecteur pour accéder aux bases de données\n",
    "\n",
    "Pour mettre en place ce connecteur, on utlise le package SQLAlchemy.\n",
    "\n",
    "Suivant le type de base de données, on utilisera différents codes mais la structure du code est toujours la même"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# on importe l'outil de connexion\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On crée une connexion\n",
    "```python\n",
    "connexion=create_engine(\"sqlite:///(...).sqlite\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On utlise une des fonctions de Pandas pour charger les données\n",
    "```python\n",
    "requete=\"\"\"select ... from ...\"\"\"\n",
    "frame_sql=pd.read_sql_query(requete,connexion)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercices :**\n",
    "    \n",
    "Importez la base de données SQLite salaries et récupérez la table Salaries dans un DataFrame \n",
    "\n",
    "*Indice :* On commence par créer la connexion et ensuite on fait la requête `select * from salaries`, la connexion se fait en utilisant l'adresse : \"sqlite:///./data/salaries.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___\n",
    "salaries = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert type(salaries) == pd.DataFrame\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage de DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour afficher un DataFrame avec des conditions, on utilise :\n",
    "    \n",
    "`df[df[\"a\"]>10]`\n",
    "\n",
    "Pour afficher uniquement certaines colonnes :\n",
    "\n",
    "`df[[\"a\",\"b\"]]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice :** Utilisez les manipulations de DataFrame pour afficher les colonnes \"price\" et \"zipcode\" avec uniquement les \"zipcode\" égaux à 75015.\n",
    "Stockez le résultats dans l'objet new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  new_df.shape[0] == 2892\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'accès aux données et sa manipulation\n",
    "\n",
    "Ajouter une variable en pandas est simple :\n",
    "    \n",
    "`df[\"new_a\"] = df[\"a\"] * 2`\n",
    "\n",
    "Avec une condition :\n",
    "    \n",
    "`df.loc[df[\"a\"]>0, \"new_a\"] = 10`\n",
    "\n",
    "ou \n",
    "\n",
    "`df[\"b\"] = np.where(df[\"a\"]<0, 1,0)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice :** Construire une nouvelle colonne à partir de la colonne \"zipcode\" avec des 1 pour chaque valeur égales à 75015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb[\"is_75015\"] = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  airbnb[\"is_75015\"].max() == 1\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifier ce qui est dans une colonne est simple en pandas, si on utilise un type spécial, on utilisera :\n",
    "    \n",
    "- pour une donnée textuelle :\n",
    "    `df[\"col_test\"].str.___`, ___ peut être remplacé par n'importe quelle méthode liée aux chaînes de caractères\n",
    "\n",
    "- pour une donnée de date :\n",
    "    `df[\"col_test\"].dt.___`, ___ peut être remplacé par n'importe quelle méthode liée aux objets datetime de python\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice :** Extraire deux colonnes avec le jour et le mois à partir de la colonne DATE_OUVERTURE du data frame bce_uai en utlisant `.dt.day` et `.dt.month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_uai[\"jour_ouverture\"] = ___\n",
    "bce_uai[\"mois_ouverture\"] = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  bce_uai[\"jour_ouverture\"].min() == 1\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice avancé :**\n",
    "    Utilisez des transformations pour rendre la colonne price de airbnb numérique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on utilisera pd.to_numeric()\n",
    "\n",
    "airbnb[\"price_num\"] = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert  airbnb[\"price_num\"].dtype == np.number\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les tris avec Pandas \n",
    "\n",
    "Pour effectuer des tris, on utilise :\n",
    "- `.sort_index()` pour le tri des index\n",
    "- `.sort_values()` pour le tri des données\n",
    "- `.rank()` affiche le rang des observations\n",
    "\n",
    "Il peut y avoir plusieurs tris dans la même opération. Dans ce cas, on utilise des listes de colonnes :\n",
    "```python\n",
    "frame.sort_values([\"col_1\",\"col_2\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :** \n",
    "    \n",
    "Triez les données sur les salaires en se basant sur le BasePay et le JobTitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_sorted = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert salaries_sorted[\"JobTitle\"].min() == salaries_sorted[\"JobTitle\"].iloc(0)\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportez des fichiers \n",
    "\n",
    "La plupart des outils d'importation existent en exportation, on utilise :\n",
    "```\n",
    "frame.to_csv(\"fichier.csv\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Exportez les données salaries dans un fichier Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les statistiques simples\n",
    "\n",
    "Les Dataframe possèdent de nombreuses méthodes pour calculer des statistiques simples :\n",
    "- `.sum(axis=0)` permet de faire une somme par colonne\n",
    "- `.sum(axis=1)` permet de faire une somme par ligne\n",
    "- `.min()` et `.max()` donnent le minimum par colonne\n",
    "- `.idxmin()` et `.idxmax()` donnent l’index du minimum et du maximum\n",
    "- `.describe()` affiche un tableau de statistiques descriptives par colonne\n",
    "- `.corr()` pour calculer la corrélation entre les colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Obtenir les moyennes et variances de la colonne `TotalPay` pour les données Salaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(salaries[___].___())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Le traitement des données manquantes\n",
    "\n",
    "- Les données manquantes sont identifiées par `NaN`\n",
    "\n",
    "\n",
    "- `.dropna()` permet de retirer les données manquantes dans un objet Series et l’ensemble d’une ligne dans le cas d’un DataFrame\n",
    "- Pour éliminer par colonne, on utilise `.dropna(axis=1)`\n",
    "- Remplacer toutes les données manquantes `.fillna(valeur)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les jointures avec Pandas\n",
    "\n",
    "On veut joindre des jeux de données en utilisant des clés (variables communes)\n",
    "\n",
    "- `pd.merge()` permet de joindre deux DataFrame, on utilise comme options `on='key'`\n",
    "\n",
    "- On peut utiliser comme option `how=`, on peut avoir :\n",
    "    - `left` dans ce cas, on garde le jeu de données à gauche et pour les données de droite des valeurs manquantes sont ajoutées.\n",
    "    - `outer`, on garde toutes les valeurs des deux jeux de données\n",
    "    - ...\n",
    "\n",
    "- On peut avoir plusieurs clés et faire une jointure sur les deux clés `on=['key1','key2']`\n",
    "\n",
    "Pour plus de détails : <http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.merge.html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Joindre deux dataframes (credit1 et credit2). On commence par importer `credit1.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit1 = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_merged = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vérifier que vous avez bien répondu à l'exercice, soumettre cette cellule\n",
    "# on utilise maj + Entrée\n",
    "assert credit_merged.shape[1] == 31\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gestion des duplications\n",
    "\n",
    "- On utilise `.duplicated()` ou `.drop_duplicates()` dans le cas où on désire effacer les lignes se répétant\n",
    "\n",
    "\n",
    "- On peut se concentrer sur une seule variables en entrant directement le nom de la variable. Dans ce cas, c’est la première apparition qui compte. Si on veut prendre la dernière apparition, on utilise l’option `keep=\"last\"`. On pourra avoir :\n",
    "```python\n",
    "frame1.drop_duplicates([\"col_0\",\"col_1\"],keep=\"last\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Discrétisation\n",
    "\n",
    "Pour discrétiser, on utilise la fonction `pd.cut()`, on va définir une liste de points pour discrétiser et on entre cette liste comme second paramètre de la fonction.\n",
    "\n",
    "Une fois discrétisé, on peut afficher les modalités obtenues en utilisant `.categories`\n",
    "\n",
    "On peut aussi compter les occurrence en utilisant `pd.value_counts()`\n",
    "\n",
    "Il est aussi possible d’entrer le nombre de segments comme second paramètre\n",
    "\n",
    "On utilisera aussi `qcut()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Créez une variable dans le dataframe AirBnB pour obtenir 5 niveaux de prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb[\"price_disc\"] = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert airbnb[\"price_disc\"].dtype = \"category\"\n",
    "print(\"Bravo !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Les tableaux croisés avec Pandas\n",
    "\n",
    "Les DataFrame possèdent des méthodes pour générer des tableaux croisés, notamment :\n",
    "```python\n",
    "frame1.pivot_table()\n",
    "```\n",
    "Cette méthode permet de gérer de nombreux cas avec des fonctions standards et sur mesure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "Afficher un tableau Pivot pour les données AirBnB. On veut afficher les moyenne des prix en fonction de deux colonnes du DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L'utilisation de GroupBy sur des DataFrame\n",
    "\n",
    "- `.groupby` permet de rassembler des observations en fonction d’une variable dite de groupe\n",
    "\n",
    "\n",
    "- Par exemple, `frame.groupby('X').mean()` donnera les moyennes par groupes de `X`\n",
    "\n",
    "\n",
    "- On peut aussi utiliser `.size()` pour connaître la taille des groupes et utiliser d’autres fonctions (`.sum()`)\n",
    "\n",
    "\n",
    "- On peut effectuer de nombreuses opérations de traitement avec le groupby\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercice :**\n",
    "    \n",
    "- Données sur les salaires\n",
    "\n",
    "\n",
    "- On utilise le `groupby()` pour rassembler les types d’emploi\n",
    "\n",
    "\n",
    "- Et on calcule des statistiques pour chaque type\n",
    "\n",
    "\n",
    "On peut utiliser la méthode `.agg()` avec par exemple `'mean'` comme paramètre\n",
    "\n",
    "On utilise aussi fréquemment la méthode `.apply()` combinée à une fonction lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de transformation Python\n",
    "\n",
    "Nous avons vu les fonctions lors de la pemère partie de la formation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans une fonction, on pourra utiliser directement le code d'exploration avec peu de changements.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice :**\n",
    "Construire une fonction capable de charger des données, de les transformer et de sauvegarder le résultat dans un fichier\n",
    "\n",
    "*Quelques indications*\n",
    "\n",
    "On utilisera python et pandas, on complètera la fonction ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def transfo(file_name, \n",
    "            folder_name,\n",
    "            output_file_name,\n",
    "            output_folder_name,\n",
    "            sep_csv = \",\"\n",
    "           ):\n",
    "    \"\"\"\n",
    "    This function should load a file (csv), clean it and export it to Excel\n",
    "    Here are the steps:\n",
    "     - Remove missing values \n",
    "     - Transform dates to Python date format\n",
    "     - Drop duplicated rows\n",
    "    This function should return 0 if all OK / 1 if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # on commence par importer la donnée en vérifiant qu'elle se trouve dans le répertoire voulu\n",
    "        # pd.read_csv()\n",
    "        \n",
    "\n",
    "        # on applique les transformations en utlisant les outils de pandas\n",
    "        # on supprime les données manquantes\n",
    "        # .dropna()\n",
    "        \n",
    "        \n",
    "        # on essaye de transformer les colonnes de date en format date python\n",
    "        # pd.to_datetime()\n",
    "        # si le terme \"date\" est compris dans le nom de la colonne\n",
    "        \n",
    "        \n",
    "        # on supprime les doublons\n",
    "        # .drop_duplicates()\n",
    "        \n",
    "        \n",
    "        # on exporte les données en vérifiant l'existence du répertoire\n",
    "        # .to_excel()\n",
    "        \n",
    "        return 0\n",
    "    except FileNotFoundError:\n",
    "        print(\"Attention problème de répertoire introuvable\")\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test du fonctionnement\n",
    "assert transfo(folder_name=\"./data/\", \n",
    "               file_name=\"base-dpt.csv\", \n",
    "               output_folder_name=\"./data/\", \n",
    "               output_file_name=\"base-dpt.xlsx\", \n",
    "               sep_csv = \";\") == 0\n",
    "data_temp = pd.read_excel(\"./data/base-dpt.xlsx\")\n",
    "assert data_temp.isna().sum().all() == 0\n",
    "print('Bravo!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez créé une fonction !\n",
    "\n",
    "On va continuer avec les graphiques en python !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
